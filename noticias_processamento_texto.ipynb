{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98eb5885",
   "metadata": {},
   "source": [
    "# Rotinas de processamento textuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1874481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "import datetime as dt\n",
    "nltk.download('rslp')\n",
    "nltk.download('punkt')\n",
    "\n",
    "arquivo_termos_esg = 'palavras_chave_esg.xlsx'\n",
    "base_noticias = 'base_noticias.xlsx'\n",
    "\n",
    "'''\n",
    "Remove acentos\n",
    "'''\n",
    "def remove_acentos(texto):\n",
    "    return unidecode.unidecode(texto)\n",
    "\n",
    "\n",
    "'''\n",
    "Retira espaços e tabs (trailing e dentro)\n",
    "'''\n",
    "def trim_texto(texto):\n",
    "    texto = ''.join(filter(lambda character:ord(character) < 0xff,texto))\n",
    "    texto = ' '.join(texto.split())\n",
    "    return texto\n",
    "    \n",
    "'''\n",
    "Remove termos comuns para não pesquisar\n",
    "'''\n",
    "def remove_termos_comuns(lista_empresas):\n",
    "    stopw = ['le', 'paulo','investimentos', 'brasil', 'carlos', 'rede', 'rio', 'ser', 'pao', 'time', 'joao', 'viver', 'rumo', 'oi', 'santos', 'porto', 'soma', 'construtora', 'transmissao', 'blue', 'pague', 'smart', 'log', 'nacional', 'siderurgica', 'mateus', 'cury', 'mundial', 'boa', 'caixa']\n",
    "    result = lista_empresas\n",
    "    \n",
    "    for w in stopw:\n",
    "        if w in result:\n",
    "            result.remove(w)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "'''\n",
    "Remove nomes compostos (ex Lojas Americanas > Americanas, Banco Itaú > Itaú)\n",
    "'''\n",
    "def remove_nome_composto(nome_composto):\n",
    "    termos_remover = ['são', 'do', 'de', 'da', 'das', 'dos', 'boa', 'indústria', 'indústrias', 'banco','grupo','consórcio', 'construtora', 'comércio', 'atacadista', 'varejista', 'lojas', 'conservas', 'energia', 'paulista','alimentos', 'alimentos','empresa','brasil', 's.a.', 's/a', 'participações', 'br', 'ltda', 'm.' ]\n",
    "    \n",
    "    nome = list(nome_composto.lower().split(' '))\n",
    "    i = 0\n",
    "\n",
    "    while i < len(termos_remover) and len(nome) > 1:\n",
    "        if termos_remover[i] in nome:\n",
    "            nome.remove(termos_remover[i])\n",
    "        \n",
    "        i = i+1\n",
    "    \n",
    "    return nome[0].split('-')[0]\n",
    "\n",
    "        \n",
    "    \n",
    "'''\n",
    "Faz o stemming de um texto\n",
    "'''\n",
    "def aplica_stemming_texto(texto):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    return remove_acentos(' '.join(stemmer.stem(token) for token in nltk.word_tokenize(texto)))\n",
    "\n",
    "\n",
    "'''\n",
    "Remove certas palavras de um texto\n",
    "'''\n",
    "def remove_palavras_texto(texto, lista_palavras):\n",
    "    query = texto\n",
    "    stopwords = lista_palavras\n",
    "\n",
    "    return ' '.join(  [word for word in re.split(\"\\W+\",query) if word.lower() not in stopwords])\n",
    "\n",
    "\n",
    "'''\n",
    " Conta os termos ESG num texto. A fonte dos termos é um Dataframe\n",
    "'''\n",
    "def conta_termos_esg(texto, termos):\n",
    "\n",
    "    texto_stem = aplica_stemming_texto(texto)\n",
    "\n",
    "    termos['QtdeE'] = 0\n",
    "    termos['QtdeS'] = 0\n",
    "    termos['QtdeG'] = 0\n",
    "\n",
    "    termos['QtdeE'] = termos['E'].apply(lambda x: texto_stem.count(aplica_stemming_texto(x) ) if not pd.isna(x) else 0)\n",
    "    termos['QtdeS'] = termos['S'].apply(lambda x: texto_stem.count(aplica_stemming_texto(x) ) if not pd.isna(x) else 0)\n",
    "    termos['QtdeG'] = termos['G'].apply(lambda x: texto_stem.count(aplica_stemming_texto(x) ) if not pd.isna(x) else 0)\n",
    "    \n",
    "    r =  ( sum(termos['QtdeE']) , sum(termos['QtdeS']), sum(termos['QtdeG']) )\n",
    "    \n",
    "    return r\n",
    "\n",
    "\n",
    "'''\n",
    " Verifica a qual categoria ESG o texto mais se relaciona pela soma de contagem dos termos\n",
    "'''\n",
    "def classifica_texto(texto, termos):\n",
    "    cont = conta_termos_esg(texto, termos)\n",
    "    if cont[0] > cont[1] and cont[0] > cont[2]:\n",
    "        return 'E'\n",
    "    elif cont[1] > cont[0] and cont[1] > cont[2]:\n",
    "        return 'S'\n",
    "    elif cont[2] > cont[0] and cont[2] > cont[1]:\n",
    "        return 'G'\n",
    "    else:\n",
    "        return 'Outros'\n",
    "    \n",
    "'''\n",
    "Classifica todas as noticias\n",
    "'''\n",
    "def classifica_textos_coletados(noticias):\n",
    "    dfTermos = pd.read_excel(arquivo_termos_esg)\n",
    "    \n",
    "    noticias['classificacao'] = noticias['texto_completo'].apply(lambda x : classifica_texto(x, dfTermos ) )\n",
    "    \n",
    "    return noticias\n",
    "\n",
    "\n",
    "'''\n",
    "Filtra notícias não relacionadas\n",
    "'''\n",
    "def filtra_noticias_nao_relacionadas(noticias, empresa):\n",
    "    df = noticias\n",
    "    emp_ajustada = remove_nome_composto(remove_acentos(empresa)).lower()\n",
    "    df = df[ df['texto_completo'].apply(lambda x : remove_acentos(x.lower())).str.contains(emp_ajustada)   ]\n",
    "    return df\n",
    "\n",
    "\n",
    "'''\n",
    "Filtra notícias sem classificacao\n",
    "'''\n",
    "def filtra_noticias_sem_classificacao(noticias, empresa):\n",
    "    df = noticias\n",
    "    df = df[df['classificacao'] != 'Outros' ]\n",
    "    return df\n",
    "\n",
    "\n",
    "    \n",
    "'''\n",
    " Conta a quatidade de empresas citadas em cada noticia (empresa selecionada x demais)\n",
    "'''\n",
    "def conta_mencoes_empresas(noticias, empresa, listagem_empresas):\n",
    "    df2 = noticias\n",
    "    df = noticias\n",
    "    \n",
    "    emp_ajustada = remove_acentos(remove_nome_composto(empresa.lower()))\n",
    "    empresas_ajust = list(listagem_empresas['Nome'])\n",
    "    empresas_ajust = remove_termos_comuns(list(set([remove_acentos(remove_nome_composto(i).lower()) for i in empresas_ajust])))\n",
    "\n",
    "    if emp_ajustada not in empresas_ajust:\n",
    "        empresas_ajust.append(emp_ajustada)\n",
    "\n",
    "    wordlist = list(map(str.lower, empresas_ajust))\n",
    "    wordlist = list(set(wordlist))\n",
    "    counters = df2['texto_completo'].apply(lambda t : Counter(re.findall(r'\\b[a-z0-9]+\\b', remove_palavras_texto(remove_acentos(t.lower()), list(noticias.columns)))))\n",
    "    \n",
    "    df2 = pd.concat([df2, counters.apply(pd.Series).fillna(0).astype(int)], axis=1)\n",
    "    other_words = list(set(df2.columns) - set(wordlist) - set(noticias.columns))\n",
    "    df2 = df2.drop(other_words, axis=1)\n",
    "\n",
    "    demais_empresas = list( set(wordlist).intersection(df2.columns))\n",
    "    \n",
    "    if emp_ajustada in demais_empresas:\n",
    "        demais_empresas.remove(emp_ajustada)\n",
    "\n",
    "    df2['demais_citacoes'] = df2[demais_empresas].sum(axis=1)\n",
    "\n",
    "    df2 = df2.drop(demais_empresas, axis=1)\n",
    "\n",
    "    df2.rename(columns = {emp_ajustada:'citacoes_empresa'}, inplace = True)\n",
    "    \n",
    "    return df2\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Verifica se a citação a empresa é relevante (> soma das demais ou aparecer no titulo)\n",
    "'''\n",
    "def filtra_citacao_relevante(noticias, empresa, listagem_empresas, threshold=1.0, aceitar_titulo=True, recalcular_contagem=True):\n",
    "    df2 = noticias\n",
    "    if recalcular_contagem:    \n",
    "        df2 = conta_mencoes_empresas(noticias, empresa, listagem_empresas)\n",
    "        \n",
    "    if aceitar_titulo:\n",
    "        df2['relevante'] = df2.apply(lambda row : \n",
    "                                     1 if ( row['citacoes_empresa'] > threshold*row['demais_citacoes']  or remove_acentos(empresa).lower() in remove_acentos(row['titulo'].lower()) )\n",
    "                                     else 0, axis=1)\n",
    "    else:\n",
    "        df2['relevante'] = df2.apply(lambda row : \n",
    "                                     1 if ( row['citacoes_empresa'] > threshold*row['demais_citacoes']   )\n",
    "                                     else 0, axis=1)\n",
    "    \n",
    "    \n",
    "    return df2[ df2['relevante'] == 1 ]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b885eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5546797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8877e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
